{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio as tio\n",
    "import nibabel.orientations as nio\n",
    "from einops import rearrange\n",
    "\n",
    "from transformer_maskgit import CTViT\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted from code in this repo\n",
    "spacing_xy = 0.75\n",
    "spacing_z = 1.5\n",
    "shape_xy = 480\n",
    "shape_z = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encoder = CTViT(\n",
    "    dim=512,\n",
    "    codebook_size=8192,\n",
    "    image_size=480,\n",
    "    patch_size=20,\n",
    "    temporal_patch_size=10,\n",
    "    spatial_depth=4,\n",
    "    temporal_depth=4,\n",
    "    dim_head=32,\n",
    "    heads=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pretrained_model = \"/home/fperezgarcia/.cache/huggingface/hub/datasets--ibrahimhamamci--CT-RATE/snapshots/d8fe2952748813799042cec9459ba12a99caab77/models/CT-CLIP-Related/CT-CLIP_v2.pt\"\n",
    "ckpt = torch.load(path_to_pretrained_model, weights_only=True)\n",
    "vit_state_dict = {k.replace('visual_transformer.', ''): v for k, v in ckpt.items() if k.startswith('visual_transformer.')}\n",
    "image_encoder.load_state_dict(vit_state_dict)\n",
    "image_encoder.eval().cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToSlp:\n",
    "    def __call__(self, image: tio.Image) -> tio.Image:\n",
    "        image = copy.deepcopy(image)\n",
    "\n",
    "        assert image.num_channels == 1\n",
    "        data = image.numpy()[0]\n",
    "\n",
    "        current_orientation = nio.io_orientation(image.affine)\n",
    "        target_orientation = nio.axcodes2ornt((\"S\", \"L\", \"P\"))\n",
    "        transform = nio.ornt_transform(current_orientation, target_orientation)\n",
    "\n",
    "        new_data = nio.apply_orientation(data, transform)\n",
    "        new_affine = image.affine.dot(nio.inv_ornt_aff(transform, data.shape))\n",
    "\n",
    "        image.set_data(new_data[np.newaxis].copy())\n",
    "        image.affine = new_affine\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "class ApplySlopeIntercept:\n",
    "    def __init__(self, slope: float, intercept: float):\n",
    "        self.slope = slope\n",
    "        self.intercept = intercept\n",
    "\n",
    "    def __call__(self, image: tio.Image) -> tio.Image:\n",
    "        image = copy.deepcopy(image)\n",
    "        new_data = self.slope * image.data.float() + self.intercept\n",
    "        image.set_data(new_data)\n",
    "        return image\n",
    "\n",
    "\n",
    "transforms = [\n",
    "    ToSlp(),\n",
    "    tio.Resample((spacing_z, spacing_xy, spacing_xy)),\n",
    "    tio.RescaleIntensity(in_min_max=(-1000, 1000), out_min_max=(-1, 1)),\n",
    "    tio.Clamp(-1, 1),\n",
    "    tio.CropOrPad((shape_z, shape_xy, shape_xy)),\n",
    "]\n",
    "preprocess = tio.Compose(transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = tio.datasets.Slicer(\"CTChest\").CT_chest\n",
    "preprocessed = preprocess(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = image_encoder(\n",
    "    preprocessed.data[np.newaxis].cuda(),\n",
    "    return_encoded_tokens=True,\n",
    ").cpu()\n",
    "\n",
    "encodings = rearrange(encodings, \"1 x y z c -> c x y z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_enc_x, shape_enc_y, shape_enc_z = encodings.shape[-3:]\n",
    "encodings_affine = [\n",
    "    [0, -spacing_xy * shape_xy / shape_enc_x, 0, 0],\n",
    "    [0, 0, -spacing_xy * shape_xy / shape_enc_y, 0],\n",
    "    [spacing_z * shape_z / shape_enc_z, 0, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "]\n",
    "encodings_affine = np.array(encodings_affine)\n",
    "subject_dict = {\n",
    "    f\"channel_{i}\": tio.ScalarImage(tensor=channel[np.newaxis], affine=encodings_affine)\n",
    "    for i, channel in enumerate(encodings[:5])\n",
    "}\n",
    "subject_dict[\"image\"] = preprocessed\n",
    "subject = tio.Subject(**subject_dict)\n",
    "plt.rcParams[\"image.interpolation\"] = \"bicubic\"\n",
    "subject.plot(figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tio.ToCanonical()(tio.ScalarImage(tensor=encodings, affine=encodings_affine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X = rearrange(image.data, \"c x y z -> (x y z) c\")\n",
    "pca.fit(X)\n",
    "\n",
    "pca_encodings = pca.transform(X)\n",
    "pca_encodings = rearrange(pca_encodings, \"(x y z) c -> c x y z\", x=shape_enc_x, y=shape_enc_y, z=shape_enc_z)\n",
    "pca_encodings = (pca_encodings - pca_encodings.min()) / (pca_encodings.max() - pca_encodings.min()) * 255\n",
    "pca_encodings = pca_encodings.astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
    "axes[0].imshow(rearrange(pca_encodings[:, shape_enc_x // 2], \"c y z -> z y c\")[::-1, ::-1])\n",
    "axes[1].imshow(rearrange(pca_encodings[:, :, shape_enc_y // 2], \"c x z -> z x c\")[::-1, ::-1])\n",
    "axes[2].imshow(rearrange(pca_encodings[..., shape_enc_z // 2], \"c x y -> y x c\")[::-1, ::-1]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
